\section{Numerické metody optimalisace}

\subsection{Newtonova metoda v jednorozměrné optimalisaci}
Je dána rovnice $g(x) = 0$, kde $g \in C^1(\R)$. Nechť $x_0 \in \R$. Položme
\[
    x_{k-1} = x_k - \frac{g(x_k)}{g'(x_k)}\text{, } k \in \N_0.
\]

\begin{tikzpicture}[scale=1,>=latex]
    \draw[->] (-0.5,0) -- (4,0) node[right] {};
    \draw[->] (0,-1.5) -- (0,3) node[above] {};

    \draw[domain=-0.5:4,samples=200,very thick]
        plot(\x,{0.5*(\x-1)^2 - 0.5});

    \draw[dashed,domain=-0.5:4]
        plot(\x,{0.5*(\x-1.5) - 0.375});

    \draw[] (1.5, 0.05) -- (1.5, -0.05);

    \draw[densely dotted]
        (1.5,0) -- (1.5,{0.5*(1.5-1)^2 - 0.5});

    \draw[] (2.25, 0.05) -- (2.25, -0.05);

    \node[above] at (1.5,0) {$x_0$};
    \node[below] at (2.25,0) {$x_1$};
    \node[above] at (2.6,1.4) {$g(x)$};
    \node[right] at (3,0.8) {$y = g'(x_0)\,(x - x_0) + g(x_0)$};

\end{tikzpicture}
\begin{itemize}
    \item Předpokládejme, že $g'(x_k) \not=0$ pro každé $k \in \N_0$.
    \item Pokud $x_0$ je dostatečně blízko řešení $\hat x$ rovnice $g(x)$, pak $x_k \rightarrow \hat x$.
\end{itemize}
Je dána funkce $f \in C^2(\R)$. Hledejme stacionární body funkce $f$, tj. řešme rovnici $f'(x) = 0$. Z Newtonovy metody 
pro řešení rovnic plyne, že
\[
    x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)}
\]
\textbf{Algoritmus}
\begin{enumerate}[(a)]
    \item Zvolíme $\varepsilon > 0$ a $x_0 \in \R$. Položíme $k = 0$.
    \item Vypočítáme $f'(x_k)$ a $f''(x_k)$.
    \item Je-li $|f'(x_k)| < \varepsilon$, pak algoritmus končí a $x_k$ je hledaná aproximace stacionárního bodu. V 
    opačném případě přejdeme na další krok.
    \item Položíme
    \[
        x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)}
    \]
    (nutno ověřit, že $f''(x_k) \not= 0$) hodnotu $k$ zvýšíme o 1 a jdeme na krok (b).
\end{enumerate}
% \subsection{Příklad použití Newtonovy metody}
% Je dána funkce $f(x) = x^4 - 4x^2 + 2$.
% \begin{center}
%     \begin{tikzpicture}
%         \begin{axis}[
%             domain=-2:2,
%             samples=100,
%             axis lines=middle,
%             xlabel={$x$},
%             ylabel={$f(x)$},
%             width=10cm,
%             height=8cm,
%             enlargelimits=true,
%         ]
%         \addplot[
%             blue,
%             thick
%         ] {x^4 - 4*x^2 + 2};
%         \end{axis}
%     \end{tikzpicture}
% \end{center}

\subsection{Omezení na minimalisační úlohy}
Chceme nalézt alespoň přibližně bod minima (alespoň lokálního) funkce $f: \R^n \rightarrow \R$.\\
\textbf{Postup:}
\begin{itemize}
    \item Zvolíme $x_0$ a konstruujeme posloupnost, jejíž členy jsou dány \[ x_{k+1} = x_k + \alpha_k d_k,\] kde 
    $\alpha_k \geq 0$ je \underline{délka} $k$-tého kroku a $d_k \in \R^n$ je \underline{směr} $k$-tého kroku.
    \item Vhodnou volbou délky kroku a směru se snažíme dosáhnout toho, aby $f(x_{k+1}) < f(x_k)$.
\end{itemize}

\subsection{Nepodmíněná optimalisace - Metoda největšího spádu}
V metodě největšího spádu předpokládáme, že $f \in C^1(\R^n)$.\\
\textbf{Volba směru $d_k$:}
\begin{itemize}
    \item Chceme, aby $f(x_{k+1}) < f(x_k)$, a proto za směr $d_k$ budeme volit směr poklesu, tj. prvek z $\D(f; x_k)$.
    \item Konkrétně volme $d_k = -\nabla f(x_k)$.
    \item Jestliže $\nabla f(x_k) \not= 0$, pak 
    \[
        \langle d_k, \nabla f(x)\rangle = \langle -\nabla f(x_k), \nabla f(x_k)\rangle = - \| \nabla f(x_k)\|^2 < 0,
    \] tj. $d_k \in \D_0(f; x_k) \subseteq \D(f;x_k)$.
    \item Směr $d_k = -\nabla f (x_k)$ je směr největšího poklesu v bodě $x_k$.
\end{itemize}
\textbf{Volba délky kroku $\alpha_k$:}
\begin{itemize}
    \item Buď pevná volba kroku $\alpha_k = \alpha$ pro každé $k \in \N_0$. Příliš velké $\alpha$ může zkazit konvergenci.
    \item Nebo například $\alpha_k \in \argmin_{\alpha \geq 0} f(x_k - \alpha \nabla f(x_k))$.
\end{itemize}
Příklad špatně zvoleného $\alpha$.

Mějme $f(x) = \frac{1}{2} \| x\|^2, \alpha = 11, x_0 = \begin{bmatrix}1 \\ 1\end{bmatrix}$. 
Pak $\nabla f(x) = \frac{1}{2}2 x = x$.
\begin{align*}
    x_1 &= x_0 + \alpha (-x_0) = -10 x_0 \\
    x_2 &= x_1 - \alpha x_1 = -10x_1 = (-10)^2 x_0 \\
    &\, \vdots \\
    x_k &= (-10)^k x_0 \dots \text{tedy očividně nekonverguje.}
\end{align*}
\textbf{Volba kritéria zastaveni:}
\begin{itemize}
    \item $\|\nabla f(x_k)\| < \varepsilon$.
    \item Další možnosti jsou $\| x_{k+1} - x_k\| < \varepsilon$, $|f(x_{k+1} - f(x))| < \varepsilon$, \dots
    \item Možná je i kombinace více kritérií.
\end{itemize}

\textbf{Algoritmus}
\begin{enumerate}
    \item Zvolme $x_0 \in \R^n, \varepsilon > 0$. Položme $k = 0$.
    \item Je-li $\| \nabla f(x_k)\| < \varepsilon$, pak algoritmus končí a $x_k$ je hledaná aproximace. V opačném 
    případě přejdeme na další krok.
    \item Položíme $d_k = -\nabla f(x_k)$.
    \item Nalezneme $\alpha_k \in \argmin_{\alpha \geq 0} f(x_k - \alpha \nabla f(x_k))$.
    \item Položíme $x_{k+1} = x_k - \alpha_k \nabla f(x_k)$. Zvýšíme hodnotu $k$ o 1 a jdeme na krok (b).
\end{enumerate}

\subsection{Podmíněná optimalisace - Metoda projekce gradientu}
Modifikuje metodu největšího spádu.\\
Předpokládejme $f \in C^1 (\R^n)$ a $C \subseteq \R^n$ je neprázdná, uzavřená a konvexní.\\
Nulovost gradientu již není vhodným kritériem pro zastavení.

\textbf{Algoritmus}
\begin{enumerate}[(a)]
    \item Zvolme $x_0 \in C$ a $\varepsilon > 0$. Položmě $k = 0$.
    \item Vypočteme $d_k = -\nabla f(x_k)$.
    \item Nalezneme $\alpha_k \in \argmin_{\alpha \geq 0} f(x_k - \alpha \nabla f(x_k))$.
    \item Položíme $x_{k+1} = P_C (x_k - \alpha_k \nabla f(x_k))$.
    \item Je-li $|f(x_{k+1}) - f(x_k)| < \varepsilon$, pak algoritmus končí a $x_k$ je hledaná aproximace. V opačném 
    případě zvýšíme hodnotu $k$ o 1 a jdeme na krok (b).
\end{enumerate}

\subsection{Podmíněná optimalisace - Metoda penalisačních funkcí}
Nechť $f, g_1, \dots, g_m \in C^1(\R^n)$ a je dána úloha
\[
\left.\begin{aligned}
    &\text{minimalisujte}&& f(x) \\
    &\text{za podmínky}  && g_1(x) \leq 0, \\
    & && \quad \quad \vdots \\
    & && g_m(x) \leq 0. 
\end{aligned}
\right\} (U)
\]
\begin{itemize}
    \item Chceme nahradit $(U)$ úlohami nepodmíněné optimalisace.
    \item $p(x) = \sum_{i=1}^{m} \left[\max \bc{0, g_i(x)}\right]^2 \dots$ penalisační funkce. 
\end{itemize}
Penalisační funkce zařídí, že čím dál budeme od přípustné množiny $C$, tím více budeme takové body penalisovat.

\textbf{Algoritmus}
\begin{enumerate}[(a)]
    \item Zvolme $\varepsilon > 0, c_0 > 0$ a $\alpha > 1$. Položmě $k = 0$.
    \item Nalezněme bod minima $x_k$ funkce $f(x) + c_k p(x)$ na $\R^n$.
    \item Je-li $c_k p(x) < \varepsilon$, pak algoritmus končí a $x_k$ je hledaná aproximace. V opačném 
    případě zvýšíme hodnotu $k$ o 1 a jdeme na krok (b).
\end{enumerate}